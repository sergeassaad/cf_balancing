{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "def get_col_names(results_lines,mode):\n",
    "    breaks = []\n",
    "    for i,line in enumerate(results_lines):\n",
    "        if(line==''):\n",
    "            breaks.append(i)\n",
    "    if(mode=='train'):\n",
    "        start_idx = 3\n",
    "    elif(mode=='val'):\n",
    "        start_idx = breaks[0]+2\n",
    "    elif(mode=='test'):\n",
    "        start_idx = breaks[1]+2\n",
    "    else:\n",
    "        raise Exception('mode must be train,val, or test')\n",
    "        \n",
    "    metrics = results_lines[start_idx].split('|')[1:]\n",
    "    col_names = [m.strip() for m in metrics]\n",
    "    col_names_all = []\n",
    "    for i,name in enumerate(col_names):\n",
    "        col_names_all.append(name)\n",
    "        col_names_all.append(name+'_stderr')\n",
    "    col_names_all.insert(0,'idx')\n",
    "    return col_names_all\n",
    "\n",
    "def process_result(result):\n",
    "    result_processed = []\n",
    "    result_arr = result.split('|')\n",
    "    result_processed.append(int(result_arr[0].strip()))\n",
    "    for r in result_arr[1:]:\n",
    "        arr = r.split('(')\n",
    "        result_processed.append(float(arr[0].strip()))\n",
    "        result_processed.append(float(arr[1].split(')')[0]))\n",
    "    return result_processed\n",
    "\n",
    "def make_df(col_names_all,results):\n",
    "    d = []\n",
    "    for result in results:\n",
    "        arr = process_result(result)\n",
    "        d.append(arr)\n",
    "    return pd.DataFrame(d,columns=col_names_all)\n",
    "\n",
    "def process_used_configs_file(lines):\n",
    "    df = pd.DataFrame()\n",
    "    for line in lines:\n",
    "        pairs = line.split(',')\n",
    "        d = {}\n",
    "        for pair in pairs:\n",
    "            key,val = pair.split(':')\n",
    "            d[key] = val\n",
    "        df = df.append(d,ignore_index=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def process_config(config):\n",
    "    arr = config.split(',')\n",
    "    d = {}\n",
    "    for el in arr:\n",
    "        k,v = el.split('=')\n",
    "        try:\n",
    "            v = float(v)\n",
    "        except:\n",
    "            v = v\n",
    "        d[k.strip()] = v\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_df(results_name,configs_name):\n",
    "    results_file = open(results_name,'r+')\n",
    "    results_lines= results_file.read().splitlines()\n",
    "    \n",
    "    breaks = []\n",
    "    for i,line in enumerate(results_lines):\n",
    "        if(line==''):\n",
    "            breaks.append(i)\n",
    "\n",
    "    train_idx = range(5,breaks[0])\n",
    "    val_idx = range(breaks[0]+4,breaks[1])\n",
    "    test_idx = range(breaks[1]+4,breaks[2])\n",
    "\n",
    "    train_results = [results_lines[i] for i in train_idx]\n",
    "    val_results = [results_lines[i] for i in val_idx]\n",
    "    test_results = [results_lines[i] for i in test_idx]\n",
    "    \n",
    "    col_names_train = get_col_names(results_lines,'train')\n",
    "    col_names_val = get_col_names(results_lines,'val')\n",
    "    col_names_test = get_col_names(results_lines,'test')\n",
    "\n",
    "    train_df = make_df(col_names_train,train_results)\n",
    "    val_df = make_df(col_names_val,val_results)\n",
    "    test_df = make_df(col_names_test,test_results)\n",
    "    \n",
    "    configs_file = open(configs_name,'r+')\n",
    "    configs_lines= configs_file.read().splitlines()\n",
    "    l = []\n",
    "    for config in configs_lines:\n",
    "        l.append(list(process_config(config).values()))\n",
    "        \n",
    "    l = list(map(list, zip(*l)))\n",
    "    col_names = list(process_config(configs_lines[0]).keys())\n",
    "    for i,el in enumerate(l):\n",
    "        train_df[col_names[i]] = el\n",
    "        val_df[col_names[i]] = el\n",
    "        test_df[col_names[i]] = el\n",
    "    return train_df,val_df,test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make IHDP dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'ihdp100_neurips'\n",
    "plot_dir = exp_name+'_plots'\n",
    "if(save_plots):\n",
    "    if (not os.path.isdir(plot_dir)):\n",
    "        os.mkdir(plot_dir)\n",
    "        \n",
    "results_name = \"/media/common/\"+exp_name+\"/results_summary.txt\"\n",
    "configs_name = \"/media/common/\"+ exp_name+\"/configs_sorted.txt\"\n",
    "\n",
    "train_df,val_df,test_df = txt_to_df(results_name,configs_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best val PEHE_NN for each weight scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pehe</th>\n",
       "      <th>Pehe_stderr</th>\n",
       "      <th>weight_scheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.769</td>\n",
       "      <td>0.053</td>\n",
       "      <td>IPW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.063</td>\n",
       "      <td>OW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.659</td>\n",
       "      <td>0.063</td>\n",
       "      <td>MW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.647</td>\n",
       "      <td>0.046</td>\n",
       "      <td>TruncIPW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pehe  Pehe_stderr weight_scheme\n",
       "1   0.769        0.053           IPW\n",
       "11  0.660        0.063            OW\n",
       "8   0.659        0.063            MW\n",
       "4   0.647        0.046      TruncIPW"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_schemes = ['IPW','OW','MW','TruncIPW']\n",
    "argmins = [np.argmin(val_df[val_df['weight_scheme']==w]['Pehe_nn']) for w in weight_schemes]\n",
    "test_df.iloc[argmins][['Pehe','Pehe_stderr','weight_scheme']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save these configs & run on IHDP1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = ['n_prop','imb_fun','n_in','dim_prop','dim_in','p_alpha','dim_out','n_out','weight_scheme']\n",
    "best_df = test_df.iloc[argmins][hyperparams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrs = []\n",
    "for i,row in best_df.iterrows():\n",
    "    out = []\n",
    "    for k,val in row.iteritems():\n",
    "        if(k=='len'):\n",
    "            continue\n",
    "        if(type(val)==float):\n",
    "            if(val.is_integer()):\n",
    "                val = int(val)\n",
    "        if(type(val)==str):\n",
    "            val = [val]\n",
    "        out.append(k+'='+str(val))\n",
    "    with open('configs/neurips/ihdp100.txt','r') as f:\n",
    "    #     with open('configs/neurips/missing_ihdp/missing_{}.txt'.format(i),'w') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            var = line.split('=')[0]\n",
    "            if(var in best_df):\n",
    "                continue\n",
    "            elif(var=='experiments'):\n",
    "                out.append('experiments=1000')\n",
    "            elif(var=='outdir'):\n",
    "                out.append(\"outdir='/media/common/ihdp1000_neurips/{}\".format(row['weight_scheme'])+\"/'\")\n",
    "            elif(var=='datadir'):\n",
    "                out.append(\"datadir='../datasets/IHDP1000/'\")\n",
    "            elif(var=='dataform'):\n",
    "                out.append(\"dataform='ihdp_npci_1-1000.train.npz'\")\n",
    "            elif(var=='data_test'):\n",
    "                out.append(\"data_test='ihdp_npci_1-1000.test.npz'\")\n",
    "            else:\n",
    "#                 print(line.strip())\n",
    "                out.append(line.strip())\n",
    "    arrs.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = 'configs/neurips/ihdp1000/'\n",
    "weights = np.array(best_df['weight_scheme'])\n",
    "for i,arr in enumerate(arrs):\n",
    "    savepath = os.path.join(savedir,'{}.txt'.format(weights[i]))\n",
    "    with open(savepath,'w') as outfile:\n",
    "        outfile.write(\"\\n\".join(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process IHDP1000 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "exp_name = 'ihdp1000_neurips'\n",
    "\n",
    "weight_schemes = ['IPW','MW','OW','TruncIPW']\n",
    "train_all = []\n",
    "val_all = []\n",
    "test_all = []\n",
    "for w in weight_schemes:\n",
    "    \n",
    "    results_name = os.path.join('/media/common/',exp_name,w,'results_summary.txt')\n",
    "    configs_name = os.path.join('/media/common/',exp_name,w,'configs_sorted.txt')\n",
    "    results_file = open(results_name,'r+')\n",
    "    results_lines= results_file.read().splitlines()\n",
    "    breaks = []\n",
    "    for i,line in enumerate(results_lines):\n",
    "        if(line==''):\n",
    "            breaks.append(i)\n",
    "\n",
    "    train_idx = range(5,breaks[0])\n",
    "    val_idx = range(breaks[0]+4,breaks[1])\n",
    "    test_idx = range(breaks[1]+4,breaks[2])\n",
    "\n",
    "    train_results = [results_lines[i] for i in train_idx]\n",
    "    val_results = [results_lines[i] for i in val_idx]\n",
    "    test_results = [results_lines[i] for i in test_idx]\n",
    "    \n",
    "    col_names_train = get_col_names(results_lines,'train')\n",
    "    col_names_val = get_col_names(results_lines,'val')\n",
    "    col_names_test = get_col_names(results_lines,'test')\n",
    "    \n",
    "    \n",
    "    train = make_df(col_names_train,train_results)\n",
    "    val = make_df(col_names_val,val_results)\n",
    "    test = make_df(col_names_test,test_results)\n",
    "    train['weight_scheme'] = w\n",
    "    val['weight_scheme'] = w\n",
    "    test['weight_scheme'] = w\n",
    "    train_all.append(train)\n",
    "    val_all.append(val)\n",
    "    test_all.append(test)\n",
    "    \n",
    "train_all = pd.concat(train_all)\n",
    "val_all = pd.concat(val_all)\n",
    "test_all = pd.concat(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_all[['weight_scheme','Pehe','Pehe_stderr','Bias_ate','Bias_ate_stderr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_scheme</th>\n",
       "      <th>Pehe</th>\n",
       "      <th>Pehe_stderr</th>\n",
       "      <th>Bias_ate</th>\n",
       "      <th>Bias_ate_stderr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IPW</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MW</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OW</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TruncIPW</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weight_scheme   Pehe  Pehe_stderr  Bias_ate  Bias_ate_stderr\n",
       "0           IPW  0.722        0.014     0.205            0.008\n",
       "0            MW  0.659        0.017     0.176            0.008\n",
       "0            OW  0.650        0.016     0.176            0.007\n",
       "0      TruncIPW  0.632        0.013     0.186            0.008"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"$\\epsilon_{PEHE}$\"] = results[\"Pehe\"].astype(str) + ' $\\pm$ '+ results[\"Pehe_stderr\"].astype(str)\n",
    "results[\"$\\epsilon_{ATE}$\"] = results[\"Bias_ate\"].astype(str) + ' $\\pm$ '+ results[\"Bias_ate_stderr\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "weight_scheme &  $\\epsilon_{PEHE}$ &   $\\epsilon_{ATE}$ \\\\\n",
      "\\midrule\n",
      "          IPW &  0.722 $\\pm$ 0.014 &  0.205 $\\pm$ 0.008 \\\\\n",
      "           MW &  0.659 $\\pm$ 0.017 &  0.176 $\\pm$ 0.008 \\\\\n",
      "           OW &   0.65 $\\pm$ 0.016 &  0.176 $\\pm$ 0.007 \\\\\n",
      "     TruncIPW &  0.632 $\\pm$ 0.013 &  0.186 $\\pm$ 0.008 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results[['weight_scheme','$\\epsilon_{PEHE}$','$\\epsilon_{ATE}$']].to_latex(escape=False,index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
